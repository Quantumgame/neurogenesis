import argparse
import numpy as np
import matplotlib.pyplot as plt
import pylab
from mpl_toolkits.mplot3d import Axes3D
from matplotlib import cm
from matplotlib.ticker import LinearLocator, FormatStrFormatter
import scipy
from glob import glob

parser = argparse.ArgumentParser(
    description='Module to analyse the quality of the topographic maps generated by SpiNNaker')
parser.add_argument('path', help='path of .npz archive', nargs='*')
parser.add_argument('-o', '--output', type=str, help="name of the numpy archive storing simulation results",
                    dest='filename')

args = parser.parse_args()

# Wiring
n = 16
N_layer = n ** 2
S = (n, n)
# S = (256, 1)
grid = np.asarray(S)


# Function definitions

def distance(x0, x1, grid=np.asarray([16, 16]), type='euclidian'):
    x0 = np.asarray(x0)
    x1 = np.asarray(x1)
    delta = np.abs(x0 - x1)
    delta = np.where(delta > grid * .5, delta - grid, delta)

    if type == 'manhattan':
        return np.abs(delta).sum(axis=-1)
    return np.sqrt((delta ** 2).sum(axis=-1))


def sigma_and_ad(connectivity_matrix, unitary_weights=False, N_layer=256, n=16, resolution=1.):
    # Datastructure setup
    connectivity_matrix = np.copy(connectivity_matrix)
    variances = np.ones((N_layer, int(N_layer * resolution))) * np.nan
    preferred_locations = np.ones((n, n)) * np.nan
    active_synapses_indices = np.where(np.isfinite(connectivity_matrix))
    if unitary_weights:
        connectivity_matrix[active_synapses_indices] = 1.
    # Ignore the argmin, first just compute weighted variances for all possible source locations
    for target_location in xrange(N_layer):  # np.ndindex(16,16):
        for source_location in xrange(int(N_layer * resolution)):  # np.ndindex(16,16):
            # Distance must be computed between source_Location and the location of all presynaptic_neurons |pix|
            possible_sources = np.argwhere(active_synapses_indices[1] == target_location).ravel()
            top_sum = 0
            sum_of_weights = 0
            for p_s in possible_sources:
                other_source = active_synapses_indices[0][p_s]
                distances = distance(((source_location / resolution) // n, (source_location / resolution) % n),
                                     (other_source // n, other_source % n),
                                     grid) ** 2
                top_sum += connectivity_matrix[other_source, target_location] * distances
                sum_of_weights += connectivity_matrix[other_source, target_location]

            variances[target_location, source_location] = top_sum / sum_of_weights
    min_variances = np.nanmin(variances, axis=1).reshape(16, 16)
    #     print min_variances.shape
    stds = np.sqrt(min_variances)
    preferred_indices = np.argmin(variances, axis=1)
    AD = np.ones(int(N_layer)) * np.nan
    for index in range(AD.size):
        AD[index] = distance(((index) // n, (index) % n), (
        (preferred_indices[index] / resolution) // n, (preferred_indices[index] / resolution) % n),
                             grid)

    # return mean std, stds, mean AD, ADs
    return np.mean(stds), stds, np.mean(AD), AD, min_variances


paths = []
for file in args.path:
    if "*" in file:
        globbed_files = glob(file)
        for globbed_file in globbed_files:
            if "npz" in globbed_file:
                paths.append(globbed_file)
    else:
        paths.append(file)
for file in paths:
    try:
        start_time = pylab.datetime.datetime.now()
        print "\n\nAnalysing file", str(file)
        print "\n"
        data = np.load(file)
        simdata = np.array(data['sim_params']).ravel()[0]

        if 'case' in simdata:
            print "Case", simdata['case'], "analysis"
        else:
            print "Case unknown"
        print "simdata:", simdata
        simtime = int(data['simtime'])
        post_spikes = data['post_spikes']

        count_spikes = np.zeros(256)
        for id, time in post_spikes:
            count_spikes[int(id)] += 1

        target_neuron_mean_spike_rate = count_spikes / float(simtime) * 1000.

        total_target_neuron_mean_spike_rate = np.mean(target_neuron_mean_spike_rate)
        print "Target neuron spike rate", total_target_neuron_mean_spike_rate, "Hz"

        ff_last = data['final_pre_weights'].reshape(256, 256)
        lat_last = data['final_post_weights'].reshape(256, 256)
        init_ff_weights = data['init_ff_connections']
        init_lat_weights = data['init_lat_connections']

        number_ff_incoming_connections = np.count_nonzero(~np.isnan(ff_last), axis=0)
        final_mean_number_ff_synapses = np.mean(number_ff_incoming_connections)
        print "Final mean number of feedforward synapses", final_mean_number_ff_synapses

        initial_weight_mean = np.nanmean(init_ff_weights)
        print "Initial ff weight mean", initial_weight_mean, "(obviously)"

        final_weight_mean = np.nanmean(ff_last)
        print "Final ff weight mean", final_weight_mean

        final_weight_proportion = final_weight_mean / initial_weight_mean
        print "Weight as proportion of max for the initial number of synapses", final_weight_proportion

        init_mean_std, init_stds, init_mean_AD, init_AD, init_min_variances = sigma_and_ad(
            init_ff_weights,
            unitary_weights=True,
            resolution=1.)

        print "Mean sigma aff init", init_mean_std
        print "Mean AD init", init_mean_AD

        end_time = pylab.datetime.datetime.now()
        suffix = end_time.strftime("_%H%M%S_%d%m%Y")

        elapsed_time = end_time - start_time

        print "Total time elapsed -- " + str(elapsed_time)

        if args.filename:
            filename = args.filename
        else:
            filename = "analysis_" + str(suffix)

        np.savez(filename, recording_archive_name=file,
                 target_neurom_mean_spike_rate=target_neuron_mean_spike_rate,
                 final_mean_number_ff_synapses=final_mean_number_ff_synapses,
                 final_weight_proportion=final_weight_proportion,
                 init_ff_weights=init_ff_weights,
                 init_lat_connections=init_lat_weights,
                 final_pre_weights=ff_last,
                 final_post_weights=lat_last,
                 init_mean_std=init_mean_std, init_stds=init_stds, init_mean_AD=init_mean_AD,
                 init_AD=init_AD, init_min_variances=init_min_variances,
                 total_time=elapsed_time)
    except Exception as e:
        print e
